{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tackle Overfitting with Data Augmentation (Cats vs. Dogs)\n\nHere we will be using the famous `cats vs dogs` dataset to train a model that can classify images of dogs from images of cats. For this, we will create our own Convolutional Neural Network in Tensorflow and leverage Keras' image preprocessing utilities, more so this time around since Keras provides excellent support for augmenting image data. We will also need to create the helper functions to move the images around the filesystem.","metadata":{"id":"AuW-xg_bTsaF"}},{"cell_type":"code","source":"import os\nimport zipfile\nimport random\nimport shutil\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt","metadata":{"id":"dn-6c02VmqiN","tags":["graded"],"execution":{"iopub.status.busy":"2022-08-03T15:41:29.622862Z","iopub.execute_input":"2022-08-03T15:41:29.623376Z","iopub.status.idle":"2022-08-03T15:41:35.185475Z","shell.execute_reply.started":"2022-08-03T15:41:29.623344Z","shell.execute_reply":"2022-08-03T15:41:35.184468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Download the dataset from its original source. Note that the `zip` file that contains the images is unzipped under the `/tmp` directory.","metadata":{"id":"bLTQd84RUs1j"}},{"cell_type":"code","source":"# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n# And right click on the 'Download Manually' link to get a new URL to the dataset\n\n# Note: This is a very large dataset and will take some time to download\n\n!wget --no-check-certificate \\\n    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n    -O \"/tmp/cats-and-dogs.zip\"\n\nlocal_zip = '/tmp/cats-and-dogs.zip'\nzip_ref   = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('/tmp')\nzip_ref.close()","metadata":{"id":"3sd9dQWa23aj","lines_to_next_cell":2,"tags":[],"outputId":"e9947f16-5200-4848-db30-77081bcfc518","execution":{"iopub.status.busy":"2022-08-03T15:41:35.187337Z","iopub.execute_input":"2022-08-03T15:41:35.187968Z","iopub.status.idle":"2022-08-03T15:42:03.475182Z","shell.execute_reply.started":"2022-08-03T15:41:35.187930Z","shell.execute_reply":"2022-08-03T15:42:03.474145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the images are stored within the `/tmp/PetImages` directory. There is a subdirectory for each class, so one for dogs and one for cats.","metadata":{"id":"e_HsUV9WVJHL"}},{"cell_type":"code","source":"source_path = '/tmp/PetImages'\n\nsource_path_dogs = os.path.join(source_path, 'Dog')\nsource_path_cats = os.path.join(source_path, 'Cat')\n\n# Deletes all non-image files (there are two .db files bundled into the dataset)\n!find /tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n\n# os.listdir returns a list containing all files under the given path\nprint(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\nprint(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")","metadata":{"id":"DM851ZmN28J3","tags":["graded"],"outputId":"2391655a-b8aa-4114-8999-92a89830c7c7","execution":{"iopub.status.busy":"2022-08-03T15:42:03.476932Z","iopub.execute_input":"2022-08-03T15:42:03.477330Z","iopub.status.idle":"2022-08-03T15:42:04.710064Z","shell.execute_reply.started":"2022-08-03T15:42:03.477292Z","shell.execute_reply":"2022-08-03T15:42:04.707832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expected Output:**\n\n```\nThere are 12501 images of dogs.\nThere are 12501 images of cats.\n```","metadata":{"id":"G7dI86rmRGmC"}},{"cell_type":"markdown","source":"We will need a directory for cats-v-dogs, and subdirectories for training and validation. These in turn will need subdirectories for 'cats' and 'dogs'. To accomplish this, complete the `create_train_val_dirs` below:","metadata":{"id":"iFbMliudNIjW"}},{"cell_type":"code","source":"# Define root directory\nroot_dir = '/tmp/cats-v-dogs'\n\n# Empty directory to prevent FileExistsError is the function is run several times\nif os.path.exists(root_dir):\n  shutil.rmtree(root_dir)\n\n# Gcreate_train_val_dirs\ndef create_train_val_dirs(root_path):\n  \"\"\"\n  Creates directories for the train and test sets\n  \n  Args:\n    root_path (string) - the base directory path to create subdirectories from\n  \n  Returns:\n    None\n  \"\"\"  \n\n\n  os.makedirs(root_dir)\n  os.makedirs(os.path.join(root_dir, 'training'))\n  os.makedirs(os.path.join(root_dir, 'validation'))\n  os.makedirs(os.path.join(root_dir, 'training/cats'))\n  os.makedirs(os.path.join(root_dir, 'training/dogs'))\n  os.makedirs(os.path.join(root_dir, 'validation/cats'))\n  os.makedirs(os.path.join(root_dir, 'validation/dogs'))\n  \n \n  \ntry:\n  create_train_val_dirs(root_path=root_dir)\nexcept FileExistsError:\n  print(\"You should not be seeing this since the upper directory is removed beforehand\")","metadata":{"cellView":"code","id":"F-QkLjxpmyK2","tags":["graded"],"execution":{"iopub.status.busy":"2022-08-03T15:42:04.713509Z","iopub.execute_input":"2022-08-03T15:42:04.714420Z","iopub.status.idle":"2022-08-03T15:42:04.732159Z","shell.execute_reply.started":"2022-08-03T15:42:04.714314Z","shell.execute_reply":"2022-08-03T15:42:04.731318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test create_train_val_dirs function\n\nfor rootdir, dirs, files in os.walk(root_dir):\n    for subdir in dirs:\n        print(os.path.join(rootdir, subdir))","metadata":{"id":"5dhtL344OK00","tags":["graded"],"outputId":"9efc885c-b060-4ce0-979a-a0cfeb82c8df","execution":{"iopub.status.busy":"2022-08-03T15:42:04.733652Z","iopub.execute_input":"2022-08-03T15:42:04.733998Z","iopub.status.idle":"2022-08-03T15:42:04.769127Z","shell.execute_reply.started":"2022-08-03T15:42:04.733964Z","shell.execute_reply":"2022-08-03T15:42:04.768054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expected Output (directory order might vary):**\n\n``` txt\n/tmp/cats-v-dogs/training\n/tmp/cats-v-dogs/validation\n/tmp/cats-v-dogs/training/cats\n/tmp/cats-v-dogs/training/dogs\n/tmp/cats-v-dogs/validation/cats\n/tmp/cats-v-dogs/validation/dogs\n\n```","metadata":{"id":"D7A0RK3IQsvg"}},{"cell_type":"markdown","source":"Code the `split_data` function which takes in the following arguments:\n- SOURCE_DIR: directory containing the files\n\n- TRAINING_DIR: directory that a portion of the files will be copied to (will be used for training)\n\n- VALIDATION_DIR: directory that a portion of the files will be copied to (will be used for validation)\n\n- SPLIT_SIZE: determines the portion of images used for training.\n\nThe files should be randomized, so that the training set is a random sample of the files, and the validation set is made up of the remaining files.\n\nFor example, if `SOURCE_DIR` is `PetImages/Cat`, and `SPLIT_SIZE` is .9 then 90% of the images in `PetImages/Cat` will be copied to the `TRAINING_DIR` directory\nand 10% of the images will be copied to the `VALIDATION_DIR` directory.\n\nAll images should be checked before the copy, so if they have a zero file length, they will be omitted from the copying process. If this is the case then your function should print out a message such as `\"filename is zero length, so ignoring.\"`. **We should perform this check before the split so that only non-zero images are considered when doing the actual split.**","metadata":{"id":"R93T7HdE5txZ"}},{"cell_type":"code","source":"# split_data\ndef split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n\n  \"\"\"\n  Splits the data into train and test sets\n  \n  Args:\n    SOURCE_DIR (string): directory path containing the images\n    TRAINING_DIR (string): directory path to be used for training\n    VALIDATION_DIR (string): directory path to be used for validation\n    SPLIT_SIZE (float): proportion of the dataset to be used for training\n    \n  Returns:\n    None\n  \"\"\"\n  \n  source_dir_files_count = len(os.listdir(SOURCE_DIR)) # SOURCE_DIR is /Cat or /Dog with files\n\n  train_files_count = round(source_dir_files_count * SPLIT_SIZE)\n\n  shuffled_list = random.sample(os.listdir(SOURCE_DIR), source_dir_files_count)\n\n  for filename in shuffled_list[:train_files_count]:    \n    filesource = os.path.join(SOURCE_DIR, filename)\n    filedest = os.path.join(TRAINING_DIR, filename)\n    if os.path.getsize(filesource) == 0:\n      print(\"{} is zero length, so ignoring.\".format(filename))\n    else:\n      copyfile(filesource, filedest)\n\n  for filename in shuffled_list[train_files_count:]: \n    filesource = os.path.join(SOURCE_DIR, filename)\n    filedest = os.path.join(VALIDATION_DIR, filename)\n    if os.path.getsize(filesource) == 0:\n      print(\"{} is zero length, so ignoring.\".format(filename))\n    else:\n      copyfile(filesource, filedest)\n\n  ","metadata":{"cellView":"code","id":"zvSODo0f9LaU","tags":["graded"],"execution":{"iopub.status.busy":"2022-08-03T15:42:04.770710Z","iopub.execute_input":"2022-08-03T15:42:04.771360Z","iopub.status.idle":"2022-08-03T15:42:04.796244Z","shell.execute_reply.started":"2022-08-03T15:42:04.771318Z","shell.execute_reply":"2022-08-03T15:42:04.795049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test split_data function\n\n# Define paths\nCAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\nDOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n\nTRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\nVALIDATION_DIR = \"/tmp/cats-v-dogs/validation/\"\n\nTRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\nVALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n\nTRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\nVALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n\n# Empty directories in case you run this cell multiple times\nif len(os.listdir(TRAINING_CATS_DIR)) > 0:\n  for file in os.scandir(TRAINING_CATS_DIR):\n    os.remove(file.path)\nif len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n  for file in os.scandir(TRAINING_DOGS_DIR):\n    os.remove(file.path)\nif len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n  for file in os.scandir(VALIDATION_CATS_DIR):\n    os.remove(file.path)\nif len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n  for file in os.scandir(VALIDATION_DOGS_DIR):\n    os.remove(file.path)\n\n# Define proportion of images used for training\nsplit_size = .9\n\n# Run the function\n# NOTE: Messages about zero length images should be printed out\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n\n# Your function should perform copies rather than moving images so original directories should contain unchanged images\nprint(f\"\\n\\nOriginal cat's directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\nprint(f\"Original dog's directory has {len(os.listdir(DOG_SOURCE_DIR))} images\\n\")\n\n# Training and validation splits\nprint(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\nprint(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\nprint(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\nprint(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of dogs for validation\")","metadata":{"id":"FlIdoUeX9S-9","tags":["graded"],"outputId":"d1fe1e52-c344-43b7-f4ab-9be23a4e5e32","execution":{"iopub.status.busy":"2022-08-03T15:42:04.800919Z","iopub.execute_input":"2022-08-03T15:42:04.801540Z","iopub.status.idle":"2022-08-03T15:42:10.473320Z","shell.execute_reply.started":"2022-08-03T15:42:04.801337Z","shell.execute_reply":"2022-08-03T15:42:10.471978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have organized the data in a way that can be easily fed to Keras' `ImageDataGenerator`, we define the generators that will yield batches of images, both for training and validation. For this, we code the `train_val_generators` function below.\n\nSomething important to note is that the images in this dataset come in a variety of resolutions. Luckily, the `flow_from_directory` method allows us to standarize this by defining a tuple called `target_size` that will be used to convert each image to this target resolution. **For this exercise we use a `target_size` of (150, 150)**.","metadata":{"id":"Zil4QmOD_mXF"}},{"cell_type":"code","source":"# train_val_generators\ndef train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n  \"\"\"\n  Creates the training and validation data generators\n  \n  Args:\n    TRAINING_DIR (string): directory path containing the training images\n    VALIDATION_DIR (string): directory path containing the testing/validation images\n    \n  Returns:\n    train_generator, validation_generator - tuple containing the generators\n  \"\"\"\n  \n  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n  train_datagen = ImageDataGenerator(rescale=1./255,\n                                     rotation_range=40,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     shear_range=0.2,\n                                     zoom_range=0.2,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\n\n  # Pass in the appropriate arguments to the flow_from_directory method\n  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n                                                      batch_size=20,\n                                                      class_mode='binary',\n                                                      target_size=(150, 150))\n\n  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n  validation_datagen = ImageDataGenerator(rescale=1./255,\n                                     rotation_range=40,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     shear_range=0.2,\n                                     zoom_range=0.2,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\n\n  # Pass in the appropriate arguments to the flow_from_directory method\n  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n                                                      batch_size=20,\n                                                      class_mode='binary',\n                                                      target_size=(150, 150))\n  \n  return train_generator, validation_generator\n","metadata":{"cellView":"code","id":"fQrZfVgz4j2g","tags":["graded"],"execution":{"iopub.status.busy":"2022-08-03T15:42:10.478724Z","iopub.execute_input":"2022-08-03T15:42:10.481772Z","iopub.status.idle":"2022-08-03T15:42:10.499877Z","shell.execute_reply.started":"2022-08-03T15:42:10.481728Z","shell.execute_reply":"2022-08-03T15:42:10.497758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test generators\ntrain_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)","metadata":{"id":"qM7FxrjGiobD","tags":["graded"],"outputId":"57b9954f-7a9c-4b4c-95d2-543412a03052","execution":{"iopub.status.busy":"2022-08-03T15:42:10.501413Z","iopub.execute_input":"2022-08-03T15:42:10.502043Z","iopub.status.idle":"2022-08-03T15:42:11.948714Z","shell.execute_reply.started":"2022-08-03T15:42:10.502003Z","shell.execute_reply":"2022-08-03T15:42:11.947558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expected Output:**\n\n```\nFound 22498 images belonging to 2 classes.\nFound 2500 images belonging to 2 classes.\n```\n","metadata":{"id":"tiPNmSfZjHwJ"}},{"cell_type":"markdown","source":"One last step before training is to define the architecture of the model that will be trained.\n\nComplete the `create_model` function below which should return a Keras' `Sequential` model.\n\nAside from defining the architecture of the model, we should also compile it so make sure to use a `loss` function that is compatible with the `class_mode` we defined before.","metadata":{"id":"TI3oEmyQCZoO"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\n\n# GRADED FUNCTION: create_model\ndef create_model():\n  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS \n\n  model = tf.keras.models.Sequential([ \n      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n      tf.keras.layers.MaxPooling2D(2, 2),\n      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(512, activation='relu'),\n      tf.keras.layers.Dense(1, activation='sigmoid')\n  ])\n\n  \n  model.compile(optimizer=RMSprop(learning_rate=1e-4),\n                loss='binary_crossentropy',\n                metrics=['accuracy']) \n    \n  \n  return model\n","metadata":{"cellView":"code","id":"oDPK8tUB_O9e","lines_to_next_cell":2,"tags":["graded"],"execution":{"iopub.status.busy":"2022-08-03T15:42:11.956479Z","iopub.execute_input":"2022-08-03T15:42:11.959255Z","iopub.status.idle":"2022-08-03T15:42:11.977100Z","shell.execute_reply.started":"2022-08-03T15:42:11.959194Z","shell.execute_reply":"2022-08-03T15:42:11.976067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it is time to train the model! Note: Ignore the `UserWarning: Possibly corrupt EXIF data.` warnings.","metadata":{"id":"SMFNJZmTCZv6"}},{"cell_type":"code","source":"# Get the untrained model\nmodel = create_model()\n\n# Train the model\n# Note that this may take some time.\nhistory = model.fit(train_generator,\n                    epochs=15,\n                    verbose=1,\n                    validation_data=validation_generator)","metadata":{"id":"5qE1G6JB4fMn","tags":[],"outputId":"cfbe7e90-52a2-40ed-a08f-27bc8297a5ae","execution":{"iopub.status.busy":"2022-08-03T15:42:11.979767Z","iopub.execute_input":"2022-08-03T15:42:11.980104Z","iopub.status.idle":"2022-08-03T16:29:14.484695Z","shell.execute_reply.started":"2022-08-03T15:42:11.980071Z","shell.execute_reply":"2022-08-03T16:29:14.483745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once training has finished, we check the training and validation accuracy achieved at the end of each epoch.\n\n**The model should achieve a training and validation accuracy of at least 80% and the final testing accuracy should be either higher than the training one or have a 5% difference at maximum**. \n\nImage augmentation does help with overfitting but usually this comes at the expense of requiring more training time. To keep the training time reasonable, the same number of epochs as in the previous assignment are kept. ","metadata":{"id":"VGsaDMc-GMd4"}},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.show()\nprint(\"\")\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.show()","metadata":{"id":"MWZrJN4-65RC","tags":[],"outputId":"13b34d24-210d-4e50-d40a-7ae1efbf8277","execution":{"iopub.status.busy":"2022-08-03T16:29:14.487288Z","iopub.execute_input":"2022-08-03T16:29:14.488030Z","iopub.status.idle":"2022-08-03T16:29:14.830668Z","shell.execute_reply.started":"2022-08-03T16:29:14.488000Z","shell.execute_reply":"2022-08-03T16:29:14.829582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Links:\n* Kaggle Dogs vs. Cats Dataset: https://www.kaggle.com/c/dogs-vs-cats\n* DeepLearning.AI Programming Assignment: Cats vs Dogs with Data Augmentation: https://www.coursera.org/learn/convolutional-neural-networks-tensorflow/programming/oqDYf/cats-vs-dogs-with-data-augmentation","metadata":{}}]}