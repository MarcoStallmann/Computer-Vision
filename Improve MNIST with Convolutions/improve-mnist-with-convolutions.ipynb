{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"For this exercise we see if we can improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer to the model. We stop training once the accuracy goes above this amount. It should happen in less than 10 epochs, so it's ok to hard code the number of epochs for training, but our training must end once it hits the above metric. If it doesn't, then we'll need to redesign your callback. When 99.5% accuracy has been hit, we print out the string \"Reached 99.5% accuracy so cancelling training!\"\n","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:36.612548Z","iopub.execute_input":"2022-08-03T14:15:36.615911Z","iopub.status.idle":"2022-08-03T14:15:42.347198Z","shell.execute_reply.started":"2022-08-03T14:15:36.615866Z","shell.execute_reply":"2022-08-03T14:15:42.345761Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the data\n\n# Get only training set\n(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data() ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:42.351689Z","iopub.execute_input":"2022-08-03T14:15:42.352941Z","iopub.status.idle":"2022-08-03T14:15:45.112299Z","shell.execute_reply.started":"2022-08-03T14:15:42.352895Z","shell.execute_reply":"2022-08-03T14:15:45.111014Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing the data\n\nOne important step when dealing with image data is to preprocess the data. During the preprocess step we can apply transformations to the dataset that will be fed into our convolutional neural network.\n\nHere we will apply two transformations to the data:\n- Reshape the data so that it has an extra dimension. The reason for this is that commonly we will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.\n\nRemember that these tensors are of type `numpy.ndarray` so you can use functions like [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) or [divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) to complete the `reshape_and_normalize` function below:","metadata":{}},{"cell_type":"code","source":"print(training_images)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.114298Z","iopub.execute_input":"2022-08-03T14:15:45.114703Z","iopub.status.idle":"2022-08-03T14:15:45.134589Z","shell.execute_reply.started":"2022-08-03T14:15:45.114663Z","shell.execute_reply":"2022-08-03T14:15:45.131384Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(training_images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.139801Z","iopub.execute_input":"2022-08-03T14:15:45.140704Z","iopub.status.idle":"2022-08-03T14:15:45.150449Z","shell.execute_reply.started":"2022-08-03T14:15:45.140675Z","shell.execute_reply":"2022-08-03T14:15:45.148918Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# reshape_and_normalize\ndef reshape_and_normalize(images):\n\n    # Reshape the images to add an extra dimension\n    images = np.reshape(images, (60000, 28, 28, 1))\n    \n    # Normalize pixel values\n    images = np.divide(images, np.amax(images))\n\n    return images","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.152932Z","iopub.execute_input":"2022-08-03T14:15:45.153639Z","iopub.status.idle":"2022-08-03T14:15:45.162793Z","shell.execute_reply.started":"2022-08-03T14:15:45.153599Z","shell.execute_reply":"2022-08-03T14:15:45.161021Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Let's test the function:","metadata":{}},{"cell_type":"code","source":"# Reload the images in case you run this cell multiple times\n(training_images, _), _ = tf.keras.datasets.mnist.load_data() \n\n# Apply your function\ntraining_images = reshape_and_normalize(training_images)\n\nprint(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\nprint(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\nprint(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.165129Z","iopub.execute_input":"2022-08-03T14:15:45.166521Z","iopub.status.idle":"2022-08-03T14:15:45.730065Z","shell.execute_reply.started":"2022-08-03T14:15:45.166459Z","shell.execute_reply":"2022-08-03T14:15:45.728691Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Defining callback\n\nNow we create the callback that will ensure that training will stop after an accuracy of 99.5% is reached:","metadata":{}},{"cell_type":"code","source":"# Remember to inherit from the correct class\nclass myCallback(tf.keras.callbacks.Callback):\n        # Define the correct function signature for on_epoch_end\n        def on_epoch_end(self, epoch, logs={}):\n            if (logs.get('accuracy') >= 0.995):\n                print(\"\\nReached 99.5% accuracy so cancelling training!\") \n                \n                # Stop training once the above condition is met\n                self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.731852Z","iopub.execute_input":"2022-08-03T14:15:45.733084Z","iopub.status.idle":"2022-08-03T14:15:45.742561Z","shell.execute_reply.started":"2022-08-03T14:15:45.733041Z","shell.execute_reply":"2022-08-03T14:15:45.740609Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Convolutional Model\n\nFinally, we write the `convolutional_model` function. This function should return our convolutional neural network. **The model should achieve an accuracy of 99.5% or more before 10 epochs to pass this assignment.**","metadata":{}},{"cell_type":"code","source":"def convolutional_model():    \n\n    # Define the model\n    model = tf.keras.models.Sequential([ \n        \n    # Add convolutions and max pooling\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),  \n    \n    # Add the same layers as before\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n    ])     \n\n    # Compile the model\n    model.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy', \n                  metrics=['accuracy']) \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.744883Z","iopub.execute_input":"2022-08-03T14:15:45.745906Z","iopub.status.idle":"2022-08-03T14:15:45.756648Z","shell.execute_reply.started":"2022-08-03T14:15:45.745861Z","shell.execute_reply":"2022-08-03T14:15:45.754942Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Save untrained model\nmodel = convolutional_model()\n\n# Instantiate the callback class\ncallbacks = myCallback()print(f\"Your model was trained for {len(history.epoch)} epochs\")\n\n# Train model\nhistory = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:15:45.759549Z","iopub.execute_input":"2022-08-03T14:15:45.761264Z","iopub.status.idle":"2022-08-03T14:16:29.175092Z","shell.execute_reply.started":"2022-08-03T14:15:45.761222Z","shell.execute_reply":"2022-08-03T14:16:29.173265Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(f\"Your model was trained for {len(history.epoch)} epochs\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:17:20.906152Z","iopub.execute_input":"2022-08-03T14:17:20.906644Z","iopub.status.idle":"2022-08-03T14:17:20.915298Z","shell.execute_reply.started":"2022-08-03T14:17:20.906614Z","shell.execute_reply":"2022-08-03T14:17:20.913618Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Credit:\n* Derived from DeepLearning.ai TensorFlow Developer Professional Certificate Programming Assignment: Improve MNIST with convolutions","metadata":{}}]}